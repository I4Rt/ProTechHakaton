{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "1c402aa8-6614-40d2-b8ea-544bfd2ee9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install xgboost\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1262bf1-60f9-4071-87b0-ec9d4c65716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9183bbed-5a8d-4fca-b986-2d42b1c4937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data/UNIT_3_train.csv\n",
    "def create_df(filename):\n",
    "    df = pd.read_csv(filename, sep=';')\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    #     print(df.head(20))\n",
    "    # df['timestamp'] = pd.to_datetime(df['DATE_ID'])\n",
    "    df_test = df.copy()\n",
    "    # df_test.index = pd.to_datetime(df_test['DATE_ID'])\n",
    "    # df_test = df_test.drop(['DATE_ID'], axis=1)\n",
    "    df_test.fillna(0)\n",
    "    # df_test['min'] = df_test[min(df_test)]\n",
    "    \n",
    "    # df_test = df_test.drop(['PARAM_22' , 'PARAM_30', 'PARAM_31', 'PARAM_32', 'PARAM_33', 'PARAM_34'], axis=1)\n",
    "    return df_test\n",
    "\n",
    "def corr_matrix():\n",
    "    correlation_matrix = df_test.corr()\n",
    "    correlation_matrix = correlation_matrix[abs(correlation_matrix) > 0.7]\n",
    "    # correlation_matrix = correlation_matrix[(abs(correlation_matrix['Y_0']) > 0.3) | (abs(correlation_matrix['Y_2']) > 0.3) | (abs(correlation_matrix['Y_5']) > 0.3)]\n",
    "    correlation_matrix = correlation_matrix[correlation_matrix.columns.intersection(correlation_matrix.index)]\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Корреляционная матрица')\n",
    "    plt.show()\n",
    "    # correlation_matrix\n",
    "    df_test.iloc[:, -6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ef25e0b7-bde7-4968-a5aa-c73c7259981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df[['PARAM_2', 'PARAM_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a76c4e17-0b3f-4bb6-8d03-5dc242d5f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def train(df, y=None, ready_model=None):\n",
    "    # X = df\n",
    "    X = df.iloc[:, :-6]\n",
    "    # X = np.array([[f'sin_{i}', f'cos_{i}'] for i in range(1, K+1)])\n",
    "    # print(X, np.size(X))\n",
    "    # X = list(X.reshape(np.size(X),))\n",
    "    # X.append('ones')\n",
    "    # X = df[X]\n",
    "    # print(X.head(15))\n",
    "    if y is None: y = df['Y_5']\n",
    "    else: y = y\n",
    "    \n",
    "    # Разделяем данные на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # print(X_test)\n",
    "    \n",
    "    if ready_model:\n",
    "        # print('model', ready_model)\n",
    "        model = ready_model\n",
    "    # else: model = MLPRegressor(activation='relu')\n",
    "    # else: model = LinearRegression()\n",
    "    else: model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=3000)\n",
    "    # model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    # Обучаем модель\n",
    "    \n",
    "    \n",
    "    # yhat = reg.predict(X_test)\n",
    "    # Делаем предсказания на тестовой выборке\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    predictions_class = (y_pred >= 0.3).astype(int)\n",
    "    # print('pred_class\\n',predictions_class, '\\n', y_test)\n",
    "    # Оценка\n",
    "    # accuracy = (predictions_class == y_test).mean()\n",
    "    # print(f'Оценка на Y {accuracy}')\n",
    "    \n",
    "    # Оцениваем модель\n",
    "    # mae = mean_absolute_error(y_test, y_pred)\n",
    "    # print(f\"Mean absolute Error: {mae}\")\n",
    "\n",
    "    r2 = r2_score(y_test, predictions_class)\n",
    "    # print(f\"r2: {r2}\")\n",
    "\n",
    "    # mse = mean_squared_error(y_test, y_pred)\n",
    "    # print(f\"mse: {mse}\")\n",
    "\n",
    "    # mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    # print(f\"mape: {mape}\")\n",
    "\n",
    "    # print(y_test, '\\n', y_pred)\n",
    "    \n",
    "    # Для интерпретации коэффициентов модели\n",
    "    # coefficients = model.coef_\n",
    "    # intercept = model.intercept_\n",
    "    # print(f\"Coefficients: {coefficients}\")\n",
    "    # print(f\"Intercept: {intercept}\")\n",
    "    return model, r2\n",
    "\n",
    "def accuracy(df):\n",
    "    df_np = df.values \n",
    "    df_np = [1 if val[0] == val[1] else 0 for val in df_np]\n",
    "    df_np = sum(df_np)/len(df_np)\n",
    "    return df_np\n",
    "\n",
    "# print(accuracy(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "637ce5e3-025b-4933-9747-fbed64858f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_value: 0\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 1\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 2\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: -1.1176470588235294\n",
      "mean r2 epoch value: -1.1176470588235294\n",
      "n_value: 3\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 4\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 5\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 6\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 7\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 8\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "n_value: 9\n",
      "(89, 51)\n",
      "epoch: 0\n",
      "r2: 1.0\n",
      "mean r2 epoch value: 1.0\n",
      "mean r2 value: 0.7882352941176471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = None\n",
    "p = Path(\"raw_data\")\n",
    "n = 0\n",
    "n_max = 10\n",
    "r2_sum = 0\n",
    "for x in p.rglob(\"*\"):\n",
    "    if str(x)[-3:] == 'csv' and len(str(x)) < 50 and n < n_max:\n",
    "        print(f'n_value: {n}')\n",
    "        df_test = create_df(str(x))\n",
    "        print(df_test.shape)\n",
    "        r2_epoch_sum = 0\n",
    "        for i in range(1):\n",
    "            print(f'epoch: {i}')\n",
    "            model, r2 = train(df_test, model)\n",
    "            r2_epoch_sum += r2\n",
    "        print(f'mean r2 epoch value: {r2_epoch_sum/1}')\n",
    "            \n",
    "        n+=1\n",
    "        r2_sum += r2_epoch_sum\n",
    "        # r2_sum += r2\n",
    "print(f'mean r2 value: {r2_sum/n_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5611ac0-9aa1-4838-bd91-8dd04bbdb1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 160, 88, 44) (160, 88)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame()\n",
    "x_data = None\n",
    "y_data = None\n",
    "\n",
    "with open('raw_data/train_data/x_past.json', 'r') as file:\n",
    "    x_data = json.loads(file.read())\n",
    "    x_data = np.array(x_data)\n",
    "with open('raw_data/train_data/y_future.json', 'r') as file:\n",
    "    y_data = json.loads(file.read())\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "# ddt = np.zeros((160,88,132))\n",
    "dat = np.concatenate([x_data[0], x_data[1], x_data[2]], axis=-1)\n",
    "model2, _ = train(np.concatinate(dat, axis=0), y_data[0])\n",
    "print(model2)\n",
    "# dat = list(map(lambda x: pd.DataFrame(x), dat))\n",
    "# dat = pd.DataFrame(dat)\n",
    "# model2, r2 = train(dat, y_data)\n",
    "# for i in range(x_data):\n",
    "#     for j in range(x_data[i]):\n",
    "#         for k in range(x_data[i][j]):\n",
    "#             ddt[j][k]\n",
    "# for i in range(data):\n",
    "    \n",
    "\n",
    "    # for i in range(data):\n",
    "        \n",
    "\n",
    "# js_data = json.loads('raw_data/train_data/x_past.json')\n",
    "# print(js_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c49a00a-8e8c-462c-a676-b835364e7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3, _ = train(np.concatenate(dat[:150], axis=0), np.concatenate(y_data[:150], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6132bbe4-76e1-4ca6-be39-b58ca7080a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[-10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c5c01b5-1433-4bbb-ad4e-9b8651d6898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d97bd5d6-01d1-4c71-b7ff-cfe65e94989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8295454545454546\n"
     ]
    }
   ],
   "source": [
    "# print(dat[-10].shape)\n",
    "y_pred = model3.predict(dat[-1])\n",
    "\n",
    "res = pd.DataFrame({'pred': np.where(y_pred <= 0.3, 0, 1), 'real':np.where(y_data[-1] == 1, 1, 0) })\n",
    "res.head(20)\n",
    "print(accuracy(res))\n",
    "model3.save_model('saved_model_upgrade.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0d4d1ef-a1d7-4bd0-9edb-bbdecb0f3e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_pred < 0.2, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8dc4b91-9346-4f99-8b1a-9934f65e007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13350, 51)\n",
      "\n",
      "accuracy: 0.7613636363636364\n",
      "\n",
      "accuracy: 0.9204545454545454\n",
      "\n",
      "accuracy: 0.8522727272727273\n",
      "\n",
      "accuracy: 0.8522727272727273\n",
      "\n",
      "accuracy: 0.8636363636363636\n",
      "\n",
      "accuracy: 0.8977272727272727\n",
      "\n",
      "accuracy: 0.75\n",
      "\n",
      "accuracy: 0.7954545454545454\n",
      "\n",
      "accuracy: 0.8295454545454546\n",
      "\n",
      "accuracy: 0.8522727272727273\n",
      "\n",
      "accuracy: 0.9318181818181818\n",
      "\n",
      "accuracy: 0.7954545454545454\n",
      "\n",
      "accuracy: 0.9090909090909091\n",
      "\n",
      "accuracy: 0.9318181818181818\n",
      "\n",
      "accuracy: 0.9431818181818182\n",
      "\n",
      "accuracy: 0.9318181818181818\n",
      "\n",
      "accuracy: 0.7954545454545454\n",
      "\n",
      "accuracy: 0.7727272727272727\n",
      "\n",
      "accuracy: 0.6477272727272727\n",
      "\n",
      "accuracy: 0.8977272727272727\n",
      "\n",
      "accuracy: 0.6590909090909091\n",
      "\n",
      "accuracy: 0.36363636363636365\n",
      "\n",
      "accuracy: 0.5227272727272727\n",
      "\n",
      "accuracy: 0.7045454545454546\n",
      "\n",
      "accuracy: 0.7840909090909091\n",
      "\n",
      "accuracy: 0.9659090909090909\n",
      "\n",
      "accuracy: 0.9772727272727273\n",
      "\n",
      "accuracy: 0.7954545454545454\n",
      "\n",
      "accuracy: 0.13636363636363635\n",
      "\n",
      "accuracy: 0.9545454545454546\n",
      "\n",
      "accuracy: 0.9659090909090909\n",
      "\n",
      "accuracy: 0.9772727272727273\n",
      "\n",
      "accuracy: 0.9431818181818182\n",
      "\n",
      "accuracy: 0.13636363636363635\n",
      "\n",
      "accuracy: 0.19318181818181818\n",
      "\n",
      "accuracy: 0.09090909090909091\n",
      "\n",
      "accuracy: 0.17045454545454544\n",
      "\n",
      "accuracy: 0.10227272727272728\n",
      "\n",
      "accuracy: 0.011363636363636364\n",
      "\n",
      "accuracy: 0.06818181818181818\n",
      "\n",
      "accuracy: 0.09090909090909091\n",
      "\n",
      "accuracy: 0.6704545454545454\n",
      "\n",
      "accuracy: 0.8409090909090909\n",
      "\n",
      "accuracy: 0.8181818181818182\n",
      "\n",
      "accuracy: 0.8863636363636364\n",
      "\n",
      "accuracy: 0.9204545454545454\n",
      "\n",
      "accuracy: 0.9204545454545454\n",
      "\n",
      "accuracy: 0.8863636363636364\n",
      "\n",
      "accuracy: 0.9772727272727273\n",
      "\n",
      "accuracy: 0.9204545454545454\n",
      "\n",
      "accuracy: 0.6363636363636364\n",
      "\n",
      "accuracy: 0.6704545454545454\n",
      "\n",
      "accuracy: 0.9886363636363636\n",
      "\n",
      "accuracy: 0.07954545454545454\n",
      "\n",
      "accuracy: 0.0\n",
      "\n",
      "accuracy: 0.5\n",
      "\n",
      "accuracy: 0.6136363636363636\n",
      "\n",
      "accuracy: 0.5113636363636364\n",
      "\n",
      "accuracy: 0.4318181818181818\n",
      "\n",
      "accuracy: 0.4772727272727273\n",
      "\n",
      "accuracy: 0.5681818181818182\n",
      "\n",
      "accuracy: 0.6363636363636364\n",
      "\n",
      "accuracy: 0.4772727272727273\n",
      "\n",
      "accuracy: 0.5340909090909091\n",
      "\n",
      "accuracy: 0.625\n",
      "\n",
      "accuracy: 0.6022727272727273\n",
      "\n",
      "accuracy: 0.45454545454545453\n",
      "\n",
      "accuracy: 0.5227272727272727\n",
      "\n",
      "accuracy: 0.4659090909090909\n",
      "\n",
      "accuracy: 0.5340909090909091\n",
      "\n",
      "accuracy: 0.5\n",
      "\n",
      "accuracy: 0.6363636363636364\n",
      "\n",
      "accuracy: 0.6818181818181818\n",
      "\n",
      "accuracy: 0.8181818181818182\n",
      "\n",
      "accuracy: 0.8409090909090909\n",
      "\n",
      "accuracy: 0.9772727272727273\n",
      "\n",
      "accuracy: 0.9659090909090909\n",
      "\n",
      "accuracy: 0.3068181818181818\n",
      "\n",
      "accuracy: 0.3522727272727273\n",
      "\n",
      "accuracy: 0.5340909090909091\n",
      "\n",
      "accuracy: 0.48863636363636365\n",
      "\n",
      "accuracy: 0.4090909090909091\n",
      "\n",
      "accuracy: 0.4318181818181818\n",
      "\n",
      "accuracy: 0.5113636363636364\n",
      "\n",
      "accuracy: 0.42045454545454547\n",
      "\n",
      "accuracy: 0.9431818181818182\n",
      "\n",
      "accuracy: 0.9772727272727273\n",
      "\n",
      "accuracy: 0.9431818181818182\n",
      "\n",
      "accuracy: 0.7954545454545454\n",
      "\n",
      "accuracy: 0.18181818181818182\n",
      "\n",
      "accuracy: 0.6022727272727273\n",
      "\n",
      "accuracy: 0.5795454545454546\n",
      "\n",
      "accuracy: 0.4090909090909091\n",
      "\n",
      "accuracy: 0.9886363636363636\n",
      "\n",
      "accuracy: 0.0\n",
      "\n",
      "accuracy: 0.25925925925925924\n",
      "0.6382356551627383\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "n = 0\n",
    "n_max = 150\n",
    "r2_sum = 0\n",
    "# df_test1 = create_df('raw_data/UNIT_18_train.csv')\n",
    "# model1, r2 = train(df_test1)\n",
    "\n",
    "raw_big_data = None\n",
    "p = Path(\"raw_data/train_data\")\n",
    "for x in p.rglob(\"*\"):\n",
    "    if str(x)[-3:] == 'csv' and len(str(x)) < 50 and n < n_max:\n",
    "        # print(n)\n",
    "        df = create_df(str(x))\n",
    "        # print(big_data, df)\n",
    "        # pd.concat([big_data, df], ignore_index=True)\n",
    "        raw_big_data = pd.concat([raw_big_data, df], ignore_index=True) if raw_big_data is not None else df.copy()\n",
    "        n+=1\n",
    "print(raw_big_data.shape)\n",
    "X_data = raw_big_data.iloc[:-1, :-6]\n",
    "Y_data = raw_big_data.iloc[1:, -6:]\n",
    "big_data = X_data.join(Y_data)\n",
    "big_data = big_data.fillna(0)\n",
    "# big_data =pd.concat([X_data, Y_data], ignore_index=True)\n",
    "# print(big_data)\n",
    "\n",
    "\n",
    "p = Path(\"raw_data/test_data\")\n",
    "n = 0\n",
    "acc_sum = 0\n",
    "# df_test1 = create_df('raw_data/UNIT_18_train.csv')\n",
    "model1, r2 = train(big_data)\n",
    "for x in p.rglob(\"*\"):\n",
    "    if str(x)[-3:] == 'csv' and len(str(x)) < 50:\n",
    "        df_test1 = create_df(str(x))\n",
    "        # print(df_test1)\n",
    "        X_data_test = df_test1.iloc[:-1, :-6]\n",
    "        Y_data_test = df_test1.iloc[1:, -6:]\n",
    "        df_test1 = X_data_test.join(Y_data_test)\n",
    "        test_x = pd.DataFrame(df_test1.iloc[:, :-6])\n",
    "        # print(df_test1)\n",
    "        test_x = [1 if val >= 0.3 else 0 for val in model1.predict(test_x)]\n",
    "        data = pd.DataFrame(df_test1.iloc[:, -1:])\n",
    "        data['Pred'] = test_x\n",
    "        # print(data)\n",
    "        acc = accuracy(data)\n",
    "        # print('click\\n', data[data['Y_5']==1])\n",
    "        # print('\\nmisclick\\n', data[(data['Y_5']==0) & (data['Pred'] == 1)])\n",
    "        # print(f'accuracy: {acc}')\n",
    "        acc_sum += acc\n",
    "        n+=1\n",
    "        # print(f'processing ({n}/96)...')\n",
    "        print(f'\\naccuracy: {acc}')\n",
    "print(acc_sum/n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cbe97e3b-e9b2-4c3f-857d-8cbca0bd5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_model('saved_model.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
